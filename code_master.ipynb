{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import scipy\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNet\n",
    "import provider\n",
    "\n",
    "BATCH_SIZE=8\n",
    "MAX_EPOCH=1\n",
    "    \n",
    "def train_part34(model_init_fn, optimizer_init_fn, MAX_EPOCH):\n",
    "\n",
    "    tf.reset_default_graph()    \n",
    "    with tf.device(device):\n",
    "\n",
    "        data_input = provider.DVR_Provider()\n",
    "        imgs_pl, pts_pl, labels_pl = CNet.placeholder_inputs(BATCH_SIZE)\n",
    "        x1=imgs_pl\n",
    "        x2=imgs_pl\n",
    "        y=labels_pl\n",
    "        \n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        \n",
    "        # Use the model function to build the forward pass.\n",
    "        scores = model_init_fn(x1,x2, is_training)\n",
    "\n",
    "        # Compute the loss like we did in Part II\n",
    "        loss = CNet.get_loss(scores,y)\n",
    "        #saver = tf.train.Saver()\n",
    "\n",
    "        # Use the optimizer_fn to construct an Optimizer, then use the optimizer\n",
    "        # to set up the training step. Asking TensorFlow to evaluate the\n",
    "        # train_op returned by optimizer.minimize(loss) will cause us to make a\n",
    "        # single update step using the current minibatch of data.\n",
    "        \n",
    "        # Note that we use tf.control_dependencies to force the model to run\n",
    "        # the tf.GraphKeys.UPDATE_OPS at each training step. tf.GraphKeys.UPDATE_OPS\n",
    "        # holds the operators that update the states of the network.\n",
    "        # For example, the tf.layers.batch_normalization function adds the running mean\n",
    "        # and variance update operators to tf.GraphKeys.UPDATE_OPS.\n",
    "        optimizer = optimizer_init_fn()\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss)\n",
    "\n",
    "    # Now we can run the computational graph many times to train the model.\n",
    "    # When we call sess.run we ask it to evaluate train_op, which causes the\n",
    "    # model to update.\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        ops = {'x1': x1,\n",
    "               'x2': x2,\n",
    "               'y': y,\n",
    "               'is_training': is_training,\n",
    "               'train_op': train_op,\n",
    "               'scores': scores,\n",
    "               'loss': loss}\n",
    "        \n",
    "        for epoch in range(MAX_EPOCH):\n",
    "            print('Starting epoch %d' % epoch)\n",
    "#            for x_np, y_np in train_dset:\n",
    " #               feed_dict = {x1: x_np,x2:x_np, y: y_np, is_training:1}\n",
    " #               loss_np, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    " #               if t % print_every == 0:\n",
    " #                   print('Iteration %d, loss = %.4f' % (t, loss_np))\n",
    " #                   check_accuracy(sess, val_dset, x1,x2, scores, is_training=is_training)\n",
    "  #                  print()\n",
    "  #              t += 1\n",
    "            train_one_epoch(sess, ops, data_input)\n",
    "            eval_one_epoch(sess, ops, data_input)\n",
    "\n",
    "            # Save the variables to disk.\n",
    "            #if epoch % 10 == 0:\n",
    "                #save_path = saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))\n",
    "                #log_string(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "def train_one_epoch(sess, ops, data_input):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = True\n",
    "    num_batches = data_input.num_train // BATCH_SIZE\n",
    "    loss_sum = 0\n",
    "    acc_a_sum = 0\n",
    "    acc_s_sum = 0\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "\n",
    "        imgs, labels = data_input.load_one_batch(BATCH_SIZE, \"train\")\n",
    "        feed_dict = {ops['x1']: imgs,\n",
    "                     ops['x2']: imgs,\n",
    "                     ops['y']: labels,\n",
    "                     ops['is_training']: is_training}\n",
    "\n",
    "        _, loss_val, pred_val = sess.run([ops['train_op'],\n",
    "                                         ops['loss'],\n",
    "                                         ops['scores']],\n",
    "                                        feed_dict=feed_dict)\n",
    "\n",
    "        loss_sum += np.mean(np.square(np.subtract(pred_val, labels)))\n",
    "        acc_a = np.abs(np.subtract(pred_val[:, 1], labels[:, 1])) < (5.0 / 180 * scipy.pi)\n",
    "        acc_a = np.mean(acc_a)\n",
    "        acc_a_sum += acc_a\n",
    "        acc_s = np.abs(np.subtract(pred_val[:, 0], labels[:, 0])) < (5.0 / 20)\n",
    "        acc_s = np.mean(acc_s)\n",
    "        acc_s_sum += acc_s\n",
    "\n",
    "    print('mean loss: %f' % (loss_sum / float(num_batches)))\n",
    "    print('accuracy (angle): %f' % (acc_a_sum / float(num_batches)))\n",
    "    print('accuracy (speed): %f' % (acc_s_sum / float(num_batches)))\n",
    "\n",
    "\n",
    "def eval_one_epoch(sess, ops, data_input):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = False\n",
    "    loss_sum = 0\n",
    "\n",
    "    num_batches = data_input.num_val // BATCH_SIZE\n",
    "    loss_sum = 0\n",
    "    acc_a_sum = 0\n",
    "    acc_s_sum = 0\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        imgs, labels = data_input.load_one_batch(BATCH_SIZE, \"val\")\n",
    "        feed_dict = {ops['x1']: imgs,\n",
    "                     ops['x2']: imgs,\n",
    "                     ops['y']: labels,\n",
    "                     ops['is_training']: is_training}\n",
    "\n",
    "        _, loss_val, pred_val = sess.run([ops['train_op'],\n",
    "                                         ops['loss'],\n",
    "                                         ops['scores']],\n",
    "                                        feed_dict=feed_dict)\n",
    "        \n",
    "        loss_sum += np.mean(np.square(np.subtract(pred_val, labels)))\n",
    "        acc_a = np.abs(np.subtract(pred_val[:, 1], labels[:, 1])) < (5.0 / 180 * scipy.pi)\n",
    "        acc_a = np.mean(acc_a)\n",
    "        acc_a_sum += acc_a\n",
    "        acc_s = np.abs(np.subtract(pred_val[:, 0], labels[:, 0])) < (5.0 / 20)\n",
    "        acc_s = np.mean(acc_s)\n",
    "        acc_s_sum += acc_s\n",
    "\n",
    "    print('eval mean loss: %f' % (loss_sum / float(num_batches)))\n",
    "    print('eval accuracy (angle): %f' % (acc_a_sum / float(num_batches)))\n",
    "    print('eval accuracy (speed): %f' % (acc_s_sum / float(num_batches)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/demo/DVR/2009.jpg' 'data/demo/DVR/539.jpg' 'data/demo/DVR/2872.jpg'\n",
      " ... 'data/demo/DVR/1743.jpg' 'data/demo/DVR/824.jpg'\n",
      " 'data/demo/DVR/2427.jpg']\n",
      "Starting epoch 0\n",
      "mean loss: 42.197952\n",
      "accuracy (angle): 0.151786\n",
      "accuracy (speed): 0.265542\n",
      "eval mean loss: 0.416786\n",
      "eval accuracy (angle): 0.174202\n",
      "eval accuracy (speed): 0.390957\n",
      "Starting epoch 1\n",
      "mean loss: 0.430768\n",
      "accuracy (angle): 0.231481\n",
      "accuracy (speed): 0.427910\n",
      "eval mean loss: 0.399458\n",
      "eval accuracy (angle): 0.281915\n",
      "eval accuracy (speed): 0.444149\n",
      "Starting epoch 2\n",
      "mean loss: 0.399258\n",
      "accuracy (angle): 0.266534\n",
      "accuracy (speed): 0.475529\n",
      "eval mean loss: 0.331830\n",
      "eval accuracy (angle): 0.303191\n",
      "eval accuracy (speed): 0.486702\n",
      "Starting epoch 3\n",
      "mean loss: 0.390691\n",
      "accuracy (angle): 0.291667\n",
      "accuracy (speed): 0.483796\n",
      "eval mean loss: 0.326351\n",
      "eval accuracy (angle): 0.315160\n",
      "eval accuracy (speed): 0.468085\n",
      "Starting epoch 4\n",
      "mean loss: 0.361423\n",
      "accuracy (angle): 0.304563\n",
      "accuracy (speed): 0.504630\n",
      "eval mean loss: 0.332202\n",
      "eval accuracy (angle): 0.311170\n",
      "eval accuracy (speed): 0.470745\n",
      "Starting epoch 5\n",
      "mean loss: 0.388130\n",
      "accuracy (angle): 0.314153\n",
      "accuracy (speed): 0.492725\n",
      "eval mean loss: 0.341770\n",
      "eval accuracy (angle): 0.325798\n",
      "eval accuracy (speed): 0.494681\n",
      "Starting epoch 6\n",
      "mean loss: 0.366058\n",
      "accuracy (angle): 0.311839\n",
      "accuracy (speed): 0.499008\n",
      "eval mean loss: 0.310522\n",
      "eval accuracy (angle): 0.327128\n",
      "eval accuracy (speed): 0.482713\n",
      "Starting epoch 7\n",
      "mean loss: 0.356990\n",
      "accuracy (angle): 0.320437\n",
      "accuracy (speed): 0.507606\n",
      "eval mean loss: 0.308414\n",
      "eval accuracy (angle): 0.352394\n",
      "eval accuracy (speed): 0.480053\n",
      "Starting epoch 8\n",
      "mean loss: 0.371738\n",
      "accuracy (angle): 0.330357\n",
      "accuracy (speed): 0.510582\n",
      "eval mean loss: 0.306979\n",
      "eval accuracy (angle): 0.347074\n",
      "eval accuracy (speed): 0.478723\n",
      "Starting epoch 9\n",
      "mean loss: 0.356517\n",
      "accuracy (angle): 0.329696\n",
      "accuracy (speed): 0.508929\n",
      "eval mean loss: 0.330407\n",
      "eval accuracy (angle): 0.355053\n",
      "eval accuracy (speed): 0.505319\n",
      "Starting epoch 10\n",
      "mean loss: 0.341886\n",
      "accuracy (angle): 0.339616\n",
      "accuracy (speed): 0.508267\n",
      "eval mean loss: 0.297999\n",
      "eval accuracy (angle): 0.360372\n",
      "eval accuracy (speed): 0.493351\n",
      "Starting epoch 11\n",
      "mean loss: 0.338491\n",
      "accuracy (angle): 0.344907\n",
      "accuracy (speed): 0.515873\n",
      "eval mean loss: 0.290778\n",
      "eval accuracy (angle): 0.384309\n",
      "eval accuracy (speed): 0.490691\n",
      "Starting epoch 12\n",
      "mean loss: 0.323529\n",
      "accuracy (angle): 0.353505\n",
      "accuracy (speed): 0.523479\n",
      "eval mean loss: 0.294884\n",
      "eval accuracy (angle): 0.375000\n",
      "eval accuracy (speed): 0.496011\n",
      "Starting epoch 13\n",
      "mean loss: 0.341480\n",
      "accuracy (angle): 0.363095\n",
      "accuracy (speed): 0.519841\n",
      "eval mean loss: 0.315586\n",
      "eval accuracy (angle): 0.373670\n",
      "eval accuracy (speed): 0.500000\n",
      "Starting epoch 14\n",
      "mean loss: 0.335571\n",
      "accuracy (angle): 0.352844\n",
      "accuracy (speed): 0.520172\n",
      "eval mean loss: 0.286436\n",
      "eval accuracy (angle): 0.392287\n",
      "eval accuracy (speed): 0.502660\n",
      "Starting epoch 15\n",
      "mean loss: 0.331093\n",
      "accuracy (angle): 0.369378\n",
      "accuracy (speed): 0.527778\n",
      "eval mean loss: 0.283019\n",
      "eval accuracy (angle): 0.384309\n",
      "eval accuracy (speed): 0.496011\n",
      "Starting epoch 16\n",
      "mean loss: 0.336746\n",
      "accuracy (angle): 0.368056\n",
      "accuracy (speed): 0.527778\n",
      "eval mean loss: 0.284083\n",
      "eval accuracy (angle): 0.397606\n",
      "eval accuracy (speed): 0.482713\n",
      "Starting epoch 17\n",
      "mean loss: 0.333373\n",
      "accuracy (angle): 0.365741\n",
      "accuracy (speed): 0.533399\n",
      "eval mean loss: 0.294934\n",
      "eval accuracy (angle): 0.386968\n",
      "eval accuracy (speed): 0.498670\n",
      "Starting epoch 18\n",
      "mean loss: 0.309827\n",
      "accuracy (angle): 0.369709\n",
      "accuracy (speed): 0.527116\n",
      "eval mean loss: 0.285433\n",
      "eval accuracy (angle): 0.398936\n",
      "eval accuracy (speed): 0.515957\n",
      "Starting epoch 19\n",
      "mean loss: 0.313647\n",
      "accuracy (angle): 0.377976\n",
      "accuracy (speed): 0.533730\n",
      "eval mean loss: 0.271652\n",
      "eval accuracy (angle): 0.398936\n",
      "eval accuracy (speed): 0.493351\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-5\n",
    "channel_1, channel_2, num_classes,c1 = 32, 16, 2, 4\n",
    "\n",
    "def model_init_fn(inputs1,inputs2, is_training):\n",
    "    model = None\n",
    "\n",
    "    model = CNet.CentralNet(channel_1, channel_2, num_classes,c1)\n",
    "\n",
    "    return model(inputs1,inputs2)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
