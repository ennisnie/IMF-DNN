{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "#import matplotlib.pyplot as plt\n",
    "import CNet\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores_np has shape:  (64, 10)\n"
     ]
    }
   ],
   "source": [
    "def conv_centralnet_test():\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.device(device):\n",
    "        #conv1\n",
    "        x1 = tf.placeholder(tf.float32)\n",
    "        conv1_w1 = tf.zeros((5, 5, 3, 6))\n",
    "        conv1_b1 = tf.zeros((6,))\n",
    "        conv1_w2 = tf.zeros((3, 3, 6, 9))\n",
    "        conv1_b2 = tf.zeros((9,))\n",
    "        fc1_w = tf.zeros((32 * 32 * 9, 10))\n",
    "        fc1_b = tf.zeros((10,))\n",
    "        feed1 = [conv1_w1, conv1_b1, conv1_w2, conv1_b2, fc1_w, fc1_b]\n",
    "        \n",
    "        #conv2\n",
    "        \n",
    "        x2 = tf.placeholder(tf.float32)\n",
    "        conv2_w1 = tf.zeros((5, 5, 3, 6))\n",
    "        conv2_b1 = tf.zeros((6,))\n",
    "        conv2_w2 = tf.zeros((3, 3, 6, 9))\n",
    "        conv2_b2 = tf.zeros((9,))\n",
    "        fc2_w = tf.zeros((32 * 32 * 9, 10))\n",
    "        fc2_b = tf.zeros((10,))\n",
    "        feed2 = [conv2_w1, conv2_b1, conv2_w2, conv2_b2, fc2_w, fc2_b]\n",
    "\n",
    "        \n",
    "        #centralnet\n",
    "        c11 = tf.zeros((32*32*6, 4))\n",
    "        c12 = tf.zeros((32*32*6, 4))\n",
    "        c21 = tf.zeros((32*32*9, 10))\n",
    "        c22 = tf.zeros((32*32*9, 10))\n",
    "        cc1 = tf.zeros((4, 10))\n",
    " \n",
    "        feedc=[c11,c12,c21,c22,cc1]\n",
    "\n",
    "        #final\n",
    "        \n",
    "        params=[feed1,feed2,feedc]\n",
    "        scores=CNet.conv_centralnet(x1,x2,params)\n",
    "    # Inputs to convolutional layers are 4-dimensional arrays with shape\n",
    "    # [batch_size, height, width, channels]\n",
    "    x1_np = np.zeros((64, 32, 32, 3))\n",
    "    x2_np = np.zeros((64, 32, 32, 3))   \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        scores_np = sess.run(scores, feed_dict={x1: x1_np,x2:x2_np})\n",
    "        print('scores_np has shape: ', scores_np.shape)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    conv_centralnet_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,) int32\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n",
      "0 (64, 32, 32, 3) (64,)\n",
      "1 (64, 32, 32, 3) (64,)\n",
      "2 (64, 32, 32, 3) (64,)\n",
      "3 (64, 32, 32, 3) (64,)\n",
      "4 (64, 32, 32, 3) (64,)\n",
      "5 (64, 32, 32, 3) (64,)\n",
      "6 (64, 32, 32, 3) (64,)\n"
     ]
    }
   ],
   "source": [
    "import GetCifar\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = GetCifar.load_cifar10()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "train_dset = GetCifar.Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = GetCifar.Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = GetCifar.Dataset(X_test, y_test, batch_size=64)\n",
    "\n",
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 5.1625\n",
      "Got 131 / 1000 correct (13.10%)\n",
      "Iteration 100, loss = 2.2713\n",
      "Got 373 / 1000 correct (37.30%)\n",
      "Iteration 200, loss = 1.3442\n",
      "Got 474 / 1000 correct (47.40%)\n",
      "Iteration 300, loss = 1.6089\n",
      "Got 484 / 1000 correct (48.40%)\n",
      "Iteration 400, loss = 1.6382\n",
      "Got 500 / 1000 correct (50.00%)\n",
      "Iteration 500, loss = 1.4475\n",
      "Got 535 / 1000 correct (53.50%)\n",
      "Iteration 600, loss = 1.3655\n",
      "Got 559 / 1000 correct (55.90%)\n",
      "Iteration 700, loss = 1.4740\n",
      "Got 540 / 1000 correct (54.00%)\n"
     ]
    }
   ],
   "source": [
    "import TR\n",
    "def train_part2(model_fn, init_fn, learning_rate):\n",
    "\n",
    "    # First clear the default graph\n",
    "    tf.reset_default_graph()\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    # Set up the computational graph for performing forward and backward passes,\n",
    "    # and weight updates.\n",
    "    with tf.device(device):\n",
    "        # Set up placeholders for the data and labels\n",
    "        x1 = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        x2 = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        \n",
    "        y = tf.placeholder(tf.int32, [None])\n",
    "        params = init_fn()           # Initialize the model parameters\n",
    "        scores = model_fn(x1,x2, params) # Forward pass of the model\n",
    "        loss = TR.training_step(scores, y, params, learning_rate)\n",
    "\n",
    "    # Now we actually run the graph many times using the training data\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize variables that will live in the graph\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "#########################################################################\n",
    "        for t, (x_np, y_np) in enumerate(train_dset):\n",
    "            # Run the graph on a batch of training data; recall that asking\n",
    "            # TensorFlow to evaluate loss will cause an SGD step to happen.\n",
    "            feed_dict = {x1: x_np,x2:x_np, y: y_np}\n",
    "            loss_np = sess.run(loss, feed_dict=feed_dict)\n",
    "           \n",
    "            # Periodically print the loss and check accuracy on the val set\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss_np))\n",
    "                TR.check_accuracy(sess, val_dset, x1,x2, scores, is_training)\n",
    "################################################################################\n",
    "\n",
    "learning_rate = 1e-2\n",
    "train_part2(CNet.conv_centralnet, TR.conv_centralnet_init, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/demo/DVR/2065.jpg' 'data/demo/DVR/803.jpg' 'data/demo/DVR/433.jpg'\n",
      " ... 'data/demo/DVR/1122.jpg' 'data/demo/DVR/3608.jpg'\n",
      " 'data/demo/DVR/275.jpg']\n",
      "(32, 66, 200, 3)\n",
      "(32, 2)\n"
     ]
    }
   ],
   "source": [
    "import provider\n",
    "data_input=provider.DVR_Provider()\n",
    "imgs, labels = data_input.load_one_batch(32 ,\"train\")\n",
    "print(imgs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
