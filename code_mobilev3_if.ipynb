{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"code_mobilev3_if.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9OviXTRY9DSo","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import tensorflow as tf\n","import numpy as np\n","import math\n","import timeit\n","import scipy\n","\n","#import matplotlib.pyplot as plt\n","\n","import provider\n","import TR\n","#%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zaUsJoN9DSu","colab_type":"code","colab":{}},"source":["USE_GPU = True\n","\n","if USE_GPU:\n","    device = '/device:GPU:0'\n","else:\n","    device = '/cpu:0'\n","\n","# Constant to control how often we print when training models\n","print_every = 100\n","\n","print('Using device: ', device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_MFMy2X9DS0","colab_type":"code","colab":{}},"source":["from mobilenet_v3_block import BottleNeck, h_swish\n","\n","class CentralNet(tf.keras.Model):\n","    def __init__(self, channel_1, channel_2,channel_3,channel_4, NUM_CLASSES,c1,c2,c3,c4):\n","        super().__init__()\n","        initializer = tf.variance_scaling_initializer(scale=2.0)\n","\n","        # mobilenet\n","        self.conv1 = tf.keras.layers.Conv2D(filters=16,kernel_size=(3, 3),strides=2,padding=\"same\")\n","        self.bn1 = tf.keras.layers.BatchNormalization()\n","        self.bneck1 = BottleNeck(in_size=16, exp_size=16, out_size=16, s=2, is_se_existing=True, NL=\"RE\", k=3)\n","        self.bneck2 = BottleNeck(in_size=16, exp_size=72, out_size=24, s=2, is_se_existing=False, NL=\"RE\", k=3)\n","        self.bneck3 = BottleNeck(in_size=24, exp_size=88, out_size=24, s=1, is_se_existing=False, NL=\"RE\", k=3)\n","        self.bneck4 = BottleNeck(in_size=24, exp_size=96, out_size=40, s=2, is_se_existing=True, NL=\"HS\", k=5)\n","        self.bneck5 = BottleNeck(in_size=40, exp_size=240, out_size=40, s=1, is_se_existing=True, NL=\"HS\", k=5)\n","        self.bneck6 = BottleNeck(in_size=40, exp_size=240, out_size=40, s=1, is_se_existing=True, NL=\"HS\", k=5)\n","        self.bneck7 = BottleNeck(in_size=40, exp_size=120, out_size=48, s=1, is_se_existing=True, NL=\"HS\", k=5)\n","        self.bneck8 = BottleNeck(in_size=48, exp_size=144, out_size=48, s=1, is_se_existing=True, NL=\"HS\", k=5)\n","        self.bneck9 = BottleNeck(in_size=48, exp_size=288, out_size=96, s=2, is_se_existing=True, NL=\"HS\", k=5)\n","        self.bneck10 = BottleNeck(in_size=96, exp_size=576, out_size=96, s=1, is_se_existing=True, NL=\"HS\", k=5)\n","        self.bneck11 = BottleNeck(in_size=96, exp_size=576, out_size=96, s=1, is_se_existing=True, NL=\"HS\", k=5)\n","\n","        self.conv2 = tf.keras.layers.Conv2D(filters=576,kernel_size=(1, 1),strides=1,padding=\"same\")\n","        self.bn2 = tf.keras.layers.BatchNormalization()\n","        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(1, 1),strides=1)\n","        self.conv3 = tf.keras.layers.Conv2D(filters=1280,\n","                                            kernel_size=(1, 1),\n","                                            strides=1,\n","                                            padding=\"same\")\n","        self.conv4 = tf.keras.layers.Conv2D(filters=NUM_CLASSES,\n","                                            kernel_size=(1, 1),\n","                                            strides=1,\n","                                            padding=\"same\",\n","                                            activation=tf.keras.activations.softmax)\n","        # fusion\n","                                     \n","        self.fc4c1 = tf.layers.Dense(c1, activation=tf.nn.relu,use_bias=False,\n","                                  kernel_initializer=initializer,\n","                                  bias_initializer=tf.zeros_initializer())\n","        self.c14c2 = tf.layers.Dense(c2, activation=tf.nn.relu,use_bias=False,\n","                                  kernel_initializer=initializer,\n","                                  bias_initializer=tf.zeros_initializer())\n","        self.fc4c2 = tf.layers.Dense(c2, activation=tf.nn.relu,use_bias=False,\n","                                  kernel_initializer=initializer,\n","                                  bias_initializer=tf.zeros_initializer())\n","        self.c24c3 = tf.layers.Dense(c3, activation=tf.nn.relu,use_bias=False,\n","                                  kernel_initializer=initializer,\n","                                  bias_initializer=tf.zeros_initializer())\n","        self.fc4c3 = tf.layers.Dense(c3, activation=tf.nn.relu,use_bias=False,\n","                                  kernel_initializer=initializer,\n","                                  bias_initializer=tf.zeros_initializer())\n","        self.c34c4 = tf.layers.Dense(c4, activation=tf.nn.relu,use_bias=False,\n","                                  kernel_initializer=initializer,\n","                                  bias_initializer=tf.zeros_initializer())\n","        self.fc4c4 = tf.layers.Dense(c4, activation=tf.nn.relu,use_bias=False,\n","                                  kernel_initializer=initializer,\n","                                  bias_initializer=tf.zeros_initializer())\n","        self.c44c5 = tf.layers.Dense(1280, activation=tf.nn.relu,use_bias=False,\n","                                  kernel_initializer=initializer,\n","                                  bias_initializer=tf.zeros_initializer())\n","        \n","        self.flatten = tf.keras.layers.Flatten()\n","        \n","        self.fc1=tf.layers.Dense(1280, activation = tf.nn.relu, \n","                        kernel_initializer=initializer)\n","        self.fc2=tf.layers.Dense(1280, activation = tf.nn.relu, \n","                        kernel_initializer=initializer)\n","        self.fc3=tf.layers.Dense(576, activation = tf.nn.relu, \n","                        kernel_initializer=initializer)\n","        self.fc4=tf.layers.Dense(num_classes, activation = None, \n","                        kernel_initializer=initializer)\n","     \n","    def call(self, x1,x2, training=None):\n","        scores = None\n","        ###x1\n","\n","        x1 = self.conv1(x1)\n","        x1 = self.bn1(x1, training=training)\n","        x1 = h_swish(x1)\n","\n","        x1 = self.bneck1(x1, training=training)\n","        x1 = self.bneck2(x1, training=training)\n","        x1 = self.bneck3(x1, training=training)\n","        h1_x1=self.flatten(x1)\n","        x1 = self.bneck4(x1, training=training)\n","        x1 = self.bneck5(x1, training=training)\n","        x1 = self.bneck6(x1, training=training)\n","        h2_x1=self.flatten(x1)\n","        x1 = self.bneck7(x1, training=training)\n","        x1 = self.bneck8(x1, training=training)\n","        h3_x1=self.flatten(x1)\n","        x1 = self.bneck9(x1, training=training)\n","        x1 = self.bneck10(x1, training=training)\n","        x1 = self.bneck11(x1, training=training)\n","        h4_x1=self.flatten(x1)\n","        x1 = self.conv2(x1)\n","        x1 = self.bn2(x1, training=training)\n","        x1 = h_swish(x1)\n","        x1 = self.avgpool(x1)\n","        x1 = self.conv3(x1)\n","        x1 = h_swish(x1)\n","        x1 = self.conv4(x1)\n","        h5_x1=self.flatten(x1)\n","        ###x2\n","\n","        x2 = self.conv1(x2)\n","        x2 = self.bn1(x2, training=training)\n","        x2 = h_swish(x2)\n","\n","        x2 = self.bneck1(x2, training=training)\n","        x2 = self.bneck2(x2, training=training)\n","        x2 = self.bneck3(x2, training=training)\n","        h1_x2=self.flatten(x2)\n","        x2 = self.bneck4(x2, training=training)\n","        x2 = self.bneck5(x2, training=training)\n","        x2 = self.bneck6(x2, training=training)\n","        h2_x2=self.flatten(x2)\n","        x2 = self.bneck7(x2, training=training)\n","        x2 = self.bneck8(x2, training=training)\n","        h3_x2=self.flatten(x2)\n","        x2 = self.bneck9(x2, training=training)\n","        x2 = self.bneck10(x2, training=training)\n","        x2 = self.bneck11(x2, training=training)\n","        h4_x2=self.flatten(x2)\n","        x2 = self.conv2(x2)\n","        x2 = self.bn2(x2, training=training)\n","        x2 = h_swish(x2)\n","        x2 = self.avgpool(x2)\n","        x2 = self.conv3(x2)\n","        x2 = h_swish(x2)\n","        x2 = self.conv4(x2)\n","        h5_x2=self.flatten(x2)\n","\n","        hc1=self.fc4c1(h1_x1)+self.fc4c1(h1_x2)\n","        hc2=self.fc4c2(h2_x1)+self.fc4c2(h2_x2)+self.c14c2(hc1)\n","        hc3=self.fc4c3(h3_x1)+self.fc4c3(h3_x2)+self.c24c3(hc2)\n","        hc4=self.fc4c4(h4_x1)+self.fc4c4(h4_x2)+self.c34c4(hc3)\n","        hc5=self.fc1(h5_x1)+self.fc1(h5_x2)+self.c44c5(hc4)\n","        dense2=self.fc2(hc5) #1280\n","        dense3=self.fc3(dense2)#1000\n","        scores= self.fc4(dense3)#num_classes\n","        return scores\n","\n","\n","def placeholder_inputs(batch_size, img_rows=66, img_cols=200, points=16384, separately=False):\n","    imgs_pl = tf.placeholder(tf.float32, shape=(batch_size, img_rows, img_cols, 3))\n","    pts_pl = tf.placeholder(tf.float32, shape=(batch_size, points, 3))\n","    if separately:\n","        speeds_pl = tf.placeholder(tf.float32, shape=(batch_size))\n","        angles_pl = tf.placeholder(tf.float32, shape=(batch_size))\n","        labels_pl = [speeds_pl, angles_pl]\n","    labels_pl = tf.placeholder(tf.float32, shape=(batch_size, 2))\n","    return imgs_pl, pts_pl, labels_pl\n","\n","\n","def get_loss(pred, label, l2_weight=0.0001):\n","    diff = tf.square(tf.subtract(pred, label))\n","    train_vars = tf.trainable_variables()\n","    l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in train_vars[1:]]) * l2_weight\n","    loss = tf.reduce_mean(diff + l2_loss)\n","\n","    return loss\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqqZwA7E9DS3","colab_type":"code","colab":{}},"source":["'''testing the net\n","tf.reset_default_graph()\n","\n","channel_1, channel_2,channel_3,channel_4, num_classes,c1,c2,c3,c4=64,128,256,512,10,64,128,256,512\n","model = CentralNet(channel_1, channel_2,channel_3,channel_4, num_classes,c1,c2,c3,c4)\n","with tf.device(device):\n","    x1 = tf.zeros((64, 32, 32,3))\n","    x2 = tf.zeros((64, 32, 32,3))\n","    scores = model(x1,x2)\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    scores_np = sess.run(scores)\n","    print(scores_np.shape)\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"KZ8oRctV9DS6","colab_type":"code","colab":{}},"source":["BATCH_SIZE=8\n","MAX_EPOCH=1\n","learning_rate = 3e-5\n","channel_1, channel_2,channel_3,channel_4, num_classes,c1,c2,c3,c4=64,128,256,512,2,64,128,256,512\n","\n","def model_init_fn(inputs1,inputs2, is_training):\n","    model = None\n","\n","    model = CentralNet(channel_1, channel_2,channel_3,channel_4, num_classes,c1,c2,c3,c4)\n","\n","    return model(inputs1,inputs2)\n","\n","def optimizer_init_fn():\n","    optimizer = None\n","\n","    optimizer = tf.train.AdamOptimizer()\n","\n","    return optimizer\n","\n","TR.train_part34(model_init_fn, optimizer_init_fn,10,device,BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYV13b3k9DS9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}